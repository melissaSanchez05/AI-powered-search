{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEDxGYC_yqTq"
      },
      "source": [
        "# SBU CSE 352 - HW 4 - Machine Learning From Scratch\n",
        "\n",
        "\n",
        "Name: [Add your name]\n",
        "\n",
        "I understand that my submission needs to be my own work: [your initials]\n",
        "\n",
        "I understand that ChatGPT / Copilot / other AI tools are not allowed: [your initials]\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: 100\n",
        "\n",
        "1. Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Only use standard packages (numpy and built-in packages like random). Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "  **Important:** Do not use scikit-learn or other packages with ML built in. The point of this is to be a learning exercise. Using linear algebra from numpy is okay (things like matrix operations or pseudoinverse, for example, but not lstsq).\n",
        "\n",
        "2. Your notebook needs to be formatted professionally.\n",
        "    - Add additional markdown blocks for your description, comments in the code, add tables and use matplotlib to produce charts where appropriate\n",
        "    - Do not show debugging output or include an excessive amount of output.\n",
        "    - Check that your PDF file is readable. For example, long lines are cut off in the PDF file. You don't have control over page breaks, so do not worry about these.\n",
        "3. Document your code. Add a short discussion of how your implementation works and your design choices.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement several machine learning algorithms and evaluate their accuracy. This will be done for a downscaled version of the MNIST digit recognition dataset.\n",
        "\n",
        "**Like in real life, some of the tasks you will be asked to do may not be possible, at least directly. In these cases, your job is to figure out why it won't work and either propose a fix (best), or provide a clear explanation why it won't work.**\n",
        "\n",
        "For example, if the problem says to do k-nearest neighbors with a dataset of a billion points, this could require too much time to do each classification so it's infeasible to evaluate its test accuracy. In this case, you could suggest randomly downsample the data to a more manageable size, which will speed things up by may lose some accuracy. In your answer, then, you should describe the problem and how you solved it and the trade-offs.\n",
        "\n",
        "# Data\n",
        "First the code below ensures you have access to the training data (a subset of the MNIST images), consisting of 100 handwritten images of each digit."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First download the repo and change the directory to be the one where the dependencies are.\n",
        "# You should only need to do this once per session. If you want to reset, do Runtime -> Disconnect and Delete Runtime\n",
        "# You can always do !pwd to see the current working directory and !ls to list current files.\n",
        "!git clone https://github.com/stanleybak/CS7320-AI.git\n",
        "%cd CS7320-AI/ML\n",
        "!ls"
      ],
      "metadata": {
        "id": "dTw87RlBzTOi",
        "outputId": "ecb23c46-6c03-42ee-c671-c415e425af8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS7320-AI'...\n",
            "remote: Enumerating objects: 2794, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 2794 (delta 7), reused 2 (delta 2), pack-reused 2781 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2794/2794), 253.18 MiB | 31.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1737/1737), done.\n",
            "/content/CS7320-AI/ML\n",
            "line_fitting.ipynb\tML_for_tictactoe.ipynb\t\t  README.md\n",
            "mini-mnist-1000.pickle\tML_for_tictactoe_self_play.ipynb\n",
            "ML_example.ipynb\tMNIST.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "ny3IAxVAyqTs",
        "outputId": "701ffcdb-ff07-46ea-a36c-d59a4520986f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABUFJREFUeJzt3U0obGEcx/EhUhY0s2MhSjYsZClh4SUTWSmFjGQplsrWWtlQysZezRDSlJTsZ2FrNRZD2VDe465vz//cZowz9/zO+X6W/547zr1976nzYp6q7+/v7xggpvp/HwDwE4QLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSTXFLqyqqvLzOIBYLBaLFfsglzMuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBX9FUxR09HRYc5ra2udWX9/v7l2e3vbmX19fZV3YCXKZDLObHp62lz7/v7u9+H8Gs64kES4kES4kES4kES4kFRV7JaoYfhi587OTnOeSqWc2dTUlLm2utr9v97c3Gyutf7NgrAD7f7+vjlfXV11Zo+Pjz4fzd/4YmeEGuFCEuFCEuFCUqQuzg4PD815Mpn05ecF9eLMy8DAgDO7urqq6DFwcYZQI1xIIlxIIlxIIlxIitSL5Nls1pyXclfh/v7eme3t7ZlrrcfDpbxI3tvba86tq/+o4YwLSYQLSYQLSYQLSZF65FtTY1+LNjU1Ff0ZHx8fzqxQKPz4mP6loaHBnF9fXzszr3eCLel02pzPzMw4s7e3t6I/9zfwyBehRriQRLiQRLiQRLiQFKlHvp+fn+Y8n89X+EiKMzo6as7j8XhZn3t7e2vOK30HoRyccSGJcCGJcCGJcCEpUo98g8z6suWlpSVzbbnv4yYSCXNe6a9bsvDIF6FGuJBEuJBEuJBEuJAUqUe+lWa9mL22tmaubW9vd2bW1lSlyuVyzsx6GV4NZ1xIIlxIIlxIIlxIitTFWWtrqzmfm5tzZkNDQ2X/vL6+Pmf2G1/sbD2a9broOzk5cWYvLy9lH8P/xhkXkggXkggXkggXkggXkkL7InlXV5cz89ouqqWlxZdj8Gu7qOPjY2c2OTlZ9ucGAS+SI9QIF5IIF5IIF5Ii9cjX6wLTrwvPcnfd8TI+Pu7MxsbGzLWnp6dl/7wg4owLSYQLSYQLSYQLSYQLSaG9q2BtqTQ4OGiunZ2ddWZnZ2fm2tfX17KOy8vi4qIzW15e9uVnhQFnXEgiXEgiXEgiXEgK7fu4ahobG53Zw8ND0X9+YmLCnKs98uV9XIQa4UIS4UIS4UIS4UJSaB/5qvHatxc2zriQRLiQRLiQRLiQJHVxZu1CMzIyYq49Pz93ZkH4QuOFhQVzvrW1VeEj0cYZF5IIF5IIF5IIF5IIF5ICeVfB2mYpFovF1tfXndnw8LC5tq2tzZnl8/nyDsxDIpEw58lk0pltbm6aa+vr64v+edbdEb9++zioOONCEuFCEuFCEuFCUiB/yzeXy5lzaycdLzs7O87s6enpp4f0T14XiD09Pc6slF13Li4uzLn1dzs4OCj6c4OM3/JFqBEuJBEuJBEuJBEuJIX2rkIQWP9md3d35tqjoyNntrKyYq4N8+Nd7iog1AgXkggXkggXkgJ5cdbd3W3OrV1o5ufnfT6av93c3Diz5+dnc+3l5aUz293dNddauwRFERdnCDXChSTChSTChSTChaRA3lXwUldX58xSqZS5dmNjw5nF43FzbTqddmbZbNZcm8lknFmhUDDXonTcVUCoES4kES4kES4kSV2cIfy4OEOoES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kES4kFb2XbynbHAF+44wLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSYQLSX8AQl0xL3R5PJ4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# if the below fails to open, then the data file is not in the current working directory (see above code block)\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "  data = pickle.load(f)\n",
        "\n",
        "im3 = data['images'][300] # 100 images of each digit\n",
        "plt.figure(figsize=(2, 2))  # Adjust size as needed\n",
        "plt.imshow(im3, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzts6NT5yqTt"
      },
      "source": [
        "# Downscaling Images\n",
        "\n",
        "MNIST images are originally 28x28. We will train our models not just on the original images, but also on downscaled images with the following sizes: 14x14, 7x7, 4x4, 2x2. The next code block shows one way to do downscaling. As you can tell from the output, we cannot expect our model's accuracy will be too high on lower resolution versions, although it's unclear how much better you can do than random chance, which should have a 10% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2wTIXhvGyqTt",
        "outputId": "aa064e3f-094c-45ab-a8d5-b3ae3e6db045"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACvCAYAAACVbcM3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG3ZJREFUeJzt3X9UVVX6+PHngiJcQBwUfwwq4KBDo+jgUkdZiT8mxzKXolmmTir+bDK0mcxycj6GLjNsctloWE2jmMtRK3+1HElLTNeoI2baVGIhhsKoGEgiyg+D/f2j5f16ORfuAe7mXvT9Wos/znOfu/dGH/E8nLPvsSillAAAAACAi3m5ewEAAAAA7k40GwAAAAC0oNkAAAAAoAXNBgAAAAAtaDYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANCCZgMAAACAFk2q2QgPD5epU6e6exm4R1F/aCqoVbgbNQh3ov48i0c0G19++aWMGzdOwsLCxNfXV0JDQ2XYsGGyevVqt66rsLBQXn31VYmLi5OQkBBp1aqV9O/fX7Zu3eowPysrSx5//HHp2LGjWK1WiYqKkiVLlsjNmzeb1Nz3Gk+tPxGRrVu3yu9//3vp2rWrWCwWGTx4sKn3LVu2TCwWi/To0aNJzg3HPLVWP/30U7FYLDV+LVu2rM5jhoeH1zhe165dNXwXMMNTa7C67Oxs8fX1FYvFIp999plLxhw2bJhYLBZ5+umnXTIe6s5T66+u52xm7N+/X6ZNmybdunUTq9UqXbp0kRkzZsilS5dcuPLGYVFKKXcu4MiRIzJkyBDp3LmzTJkyRdq3by+5ubnyn//8R7Kzs+Xs2bO23PLycvHy8pLmzZs3ytp2794tY8eOlREjRsiQIUOkWbNmsm3bNjlw4ID83//9nyQlJdlyc3NzpWfPnhIUFCRPPvmkBAcHy9GjRyU1NVVGjRolu3btajJz30s8uf5ERAYPHiwnTpyQvn37yqlTp6Rnz57y6aef1vqevLw8+eUvfykWi0XCw8Plq6++anJzw8iTazU/P18+/vhjQ3zjxo2yb98+ycjIkL59+9ZpzJ07d0pJSYld7Pz587Jo0SJ56qmn5I033mjQmlF3nlyD1Y0aNUrS09Plxo0bcvz4cenTp0+Dxtu+fbtMnjxZbty4IXPmzJE1a9a4aKUwy5Prry7nbGb16dNHrl69Ko8++qh07dpVzp07J2vWrBGr1SqnTp2S9u3ba/hONFFuNmLECBUSEqKKiooMr+Xn5zf+gu5w7tw5lZOTYxerqqpSQ4cOVS1atFAlJSW2+LJly5SIqK+++souf/LkyUpE1NWrV5vM3PcST64/pZS6cOGCqqysVEop1b17dzVo0CCn7xk/frwaOnSoGjRokOrevXuTnBtGnl6rjkRGRqquXbu6bLylS5cqEVGHDx922Zgwr6nU4EcffaR8fHzUokWLlIio48ePN2i80tJSFR4erpYsWaJERM2ZM8dFK0VdeHL91eWczayDBw/a/g++MyYi6sUXX2zQehub22+jys7Olu7du0urVq0Mr7Vt29buuPo9eLVdts/JybHlnTlzRsaNGyfBwcHi6+srffr0kQ8//NDp2iIiIiQsLMwuZrFYJD4+XsrLy+XcuXO2eHFxsYiItGvXzi6/Q4cO4uXlJT4+PiIisn79erFYLLJu3Tq7vJdfflksFovs2bNH29ww8uT6ExHp1KmTeHmZ/2d66NAh+eCDD2TVqlUOXzdbfzrmRsN4eq1Wl5GRIWfPnpVJkybZYleuXJGQkBAZPHiwqDsuqp89e1b8/f1l/PjxtY75z3/+UyIiIiQ2NrZea0LDNIUavHXrlsybN0/mzZsnv/jFLwyv16cGV6xYIVVVVTJ//nzT64DreXL9mT1nKy0tlaioKImKipLS0lJb7tWrV6VDhw4SGxsrlZWVIiISFxdn+D84Li5OgoODJTMz0+maPInbm42wsDA5ceJEvW632Lhxo+ErLCxM/Pz8JCAgQEREvv76a+nfv79kZmbKCy+8IK+99pr4+/tLfHy87Nixo15rvnz5soiItGnTxha7fT/79OnT5dSpU5Kbmytbt26VtWvXyty5c8Xf319ERBISEmTkyJHypz/9SXJzc0Xkp3sQk5KSZPr06TJixAhtc8OoKdZfTSorKyUxMVFmzJgh0dHRDnMaWn8NmRsN09RqddOmTSIids1G27ZtZe3atXLw4EHbPdZVVVUydepUCQwMlJSUlBrHO3nypGRmZsrEiRPrvBa4RlOowVWrVklRUZEsWrTI4et1rcELFy7IK6+8IsnJyeLn51fn7xuu0xTqr7rq52x+fn6yYcMGOXv2rLz44ou2vDlz5si1a9ckNTVVvL29axyvpKRESkpK7M4BmwR3X1rZt2+f8vb2Vt7e3mrAgAFqwYIFau/evaqiosKQGxYWpqZMmVLjWCtWrFAiot59911b7Le//a2Kjo5WZWVltlhVVZWKjY2t1+X9wsJC1bZtWzVw4EDDa0uXLlV+fn5KRGxfji51Xbp0SQUHB6thw4ap8vJyFRMTozp37qyuXbumfW7Ya0r15+xWpjVr1qigoCB15coVpZSq8Vam+tSfq+ZG/TWlWv3xxx9Vu3btVL9+/Ry+PmHCBGW1WtW3336rXn31VSUiaufOnbWO+eyzzyoRUadPn67TWuA6nl6Dly5dUoGBgeqtt95SSim1fv36Gm+jMluD48aNU7GxsbZj4TYqt/H0+quutnO2hQsXKi8vL3Xo0CH1/vvvKxFRq1atcjrm7VtJ9+/fX+f1uJPbmw2llMrIyFBjxoxRVqvVdqIcEhKidu3aZZdXW/Gkp6crb29vlZiYaIsVFhYqi8Wili5dqr7//nu7r6SkJCUiKi8vz/Q6Kysr1YMPPqh8fHzUqVOnDK9v3LhRDR8+XL399ttq27Ztatq0acpisajVq1cbcjdv3qxERPXr109ZLBb1ySefNNrcsNdU6q+2E/6CggIVHBys/vrXv9pitZ3w17X+XDk36q+p1OrevXuViKjXX3/d4euFhYWqQ4cOqmfPnsrX11c98cQTtY5XWVmpQkNDVUxMjOk1QA9PrsHJkyerXr162e5zr63ZMFOD6enpymKxqIyMDFuMZsO9PLn+7uTsnK28vFxFR0eriIgIFRISogYNGqSqqqpqHfPgwYOqWbNm6rHHHjO9Dk/hEc3GbeXl5SojI0MtXLhQ+fr6qubNm6uvv/7a9npNxZObm6tCQkJUXFycunXrli1+7Ngxu9/0O/r6/PPPTa/vqaeeMnTCt23evFn5+fmp3Nxcu/jUqVOV1WpVBQUFhvc8/PDDSkTUrFmzGn1uGHl6/dV2wv/kk0+qyMhIVV5ebos5O+GvS/25em40jKfX6uTJk5W3t7e6fPlyjTm3f5vXrl07hxs+75Senq5ExK6hhXt5Wg0ePXpUWSwWlZ6ebovV1mwoVXsN3rp1S/Xo0UNNnjzZLk6z4Rk8rf6qq+2c7bbjx48rEVG+vr7q3LlztY6XmZmpgoOD1a9//WtVXFxseh2eopnp+60agY+Pj/Tt21f69u0r3bp1k4SEBHn//fdl8eLFNb6noqJCxo0bJy1atJD33ntPmjX7/99SVVWViIjMnz9fhg8f7vD9kZGRptaWlJQkKSkp8sorr8gTTzxheD0lJUViYmKkY8eOdvFRo0ZJamqqnDx5Uh544AFbvLCw0PbZ36dPn5aqqqoaN+O6em445sn1V5usrCx5++23ZdWqVXLx4kVbvKysTG7duiU5OTnSsmVLCQ4Otr1Wl/pz9dxoOE+u1dLSUtmxY4c88MADhg+tuNPevXtFRKSoqEjy8vIcbvq8bdOmTeLl5SUTJkwwtQbo52k1uGDBAhk4cKBERETYNvwWFBSIiMilS5fkwoUL0rlzZ7v31FaD7777rnzzzTfy1ltv2W0gFhG5fv265OTkSNu2bcVqtda4JujjafV3J2fnbLfdrr+ysjLJysqSiIgIh3m5ubnyu9/9ToKCgmTPnj0SGBhoah0exd3dTk2+/PJLJSJq9uzZtpijTnX27NmqRYsW6tixY4Yx8vPzlYiohQsXNmgta9asUSKinnnmmRpzunXrpn7zm98Y4lu3blUiotLS0uzi48ePV1arVS1fvlyJiHrttdcabW4450n1d1tNVxcOHDjg9Dcy8+bNs3uP2frTMTdcy9NqdcuWLU5/o5eWlqZERC1YsECFhoaq3r172/2W8U5lZWWqVatWaujQoQ1eG/TwhBoMCwur9edQUFCQXb6zGly8eLHTn207duyo11rhWp5Qf7eZOWdTSqkvvvhC+fj4qISEBBUTE6M6deqkfvjhB0NeQUGBioqKUm3btlXffvttg9bmTm5vNtLT0x3ep5acnKxERK1cudIWq14869atUyKi3nnnnRrHHzx4sAoODlYXL140vHZ7M2tttmzZory8vNSkSZNqvZ9u5MiRysfHR33zzTd28fj4eOXl5aX+97//2WK3L93+7W9/U0op9fjjjys/Pz/De3XMDXueXn93qumE//vvv1c7duwwfHXv3l117txZ7dixQ/33v/+15ZutPx1zo/6aSq2OGjVKWa1Wdf36dYevFxUVqdDQUNWvXz/1448/2k76kpKSHOZv375diYj6xz/+YXoN0MOTa3Dv3r2Gn0OJiYm22+92795tyzVTg5mZmQ5/tomIGjFihNqxY4fDdUIfT64/pcyfs1VUVKiYmBgVHh6uiouL7RqPO5WUlKh+/fqpwMBA9dlnnzmd35O5/QniPXr0kJs3b8qYMWMkKipKKioq5MiRI7J161bp1KmTnDx50nZpMzw8XAYPHiypqalSUFAgnTp1ki5dusjChQsN444ZM0b8/f3l9OnTcv/994uXl5fMnDlTunTpIvn5+XL06FHJy8uTL774osa1ZWRkyMCBAyUoKEiSk5MNT6KMjY2VLl26iMhPzxgYOnSotG7dWp5++mlp3bq17N69W9LS0mTGjBny97//XUR++ozv7t27S3R0tOzfv18sFosUFhZK9+7dpUuXLvLvf/9bvLy8tMwNI0+uP5Gf/m4PHTokIiKrV68Wq9Uq06dPF5GfPm87Li6uxvcOHjxYCgoK7D4m0Gz96ZgbDePptSry02fFt2/fXh555BHZvHmzw5wpU6bIe++9JydPnpSoqCgREZk5c6Zs2LBBjh8/Lr169bLLHzdunOzevVvy8/MlKCiojn9qcKWmUIN3Sk1NlYSEBMMTxOtag3eyWCw8QdxNPLn+6nLOtnjxYlm6dKns379fhgwZIiIiy5Ytk0WLFsm//vUv20fQx8fHy65du2TatGm2vNsCAgIkPj6+vn+Ujc/d3U5aWpqaNm2aioqKUgEBAcrHx0dFRkaqxMREwxMh7+xUv/vuu1ovb3733Xe292VnZ6vJkyer9u3bq+bNm6vQ0FA1cuRI9cEHH9S6ttuby2r6Wr9+vV3+sWPH1EMPPWSbp1u3bmrZsmV2l2bHjh2rAgMDDU+a3LVrlxIRlZycrG1uGHly/SlV+6X8xYsX1/peR5u0zdafjrnRMJ5eq0op9eabbyoRUR9++KHD12/XWfXb9oqLi1VYWJjq1auX3cdYXrt2Tfn6+qqxY8eamh96NYUavJOjDeJ1rcHqRNgg7i6eXH9mz9lOnDihmjVrZvdJWEr99HHhffv2VT//+c9tH1ZQ262BYWFhDfmjbHRuv7IBAAAA4O7k9ieIAwAAALg70WwAAAAA0IJmAwAAAIAWNBsAAAAAtKDZAAAAAKAFzQYAAAAALZqZTbRYLDrXgSaqsT45mfqDI435yd3UIBzhZ2DjCwsLc/cS5Pz58+5egog0Xv21adOmUeZpCkJCQty9BI+RmZlpKo8rGwAAAAC0oNkAAAAAoAXNBgAAAAAtaDYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANCCZgMAAACAFjQbAAAAALSg2QAAAACgBc0GAAAAAC1oNgAAAABoQbMBAAAAQAuaDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtKDZAAAAAKBFM3cvAEDdeHt7m8rr2LGj0xyLxWJqrJycHFN5aHxeXq77ndHo0aNdNpaISExMjMvGeumll1w2VlVVlcvGAgDUjisbAAAAALSg2QAAAACgBc0GAAAAAC1oNgAAAABowQZxFwkMDDTEAgIC7I4ffvhhQ05ISIghtnLlSkOsvLy8AasDAAAAGh9XNgAAAABoQbMBAAAAQAuaDQAAAABa0GwAAAAA0IIN4k6Eh4cbYs8//7whNmDAAEOsR48e9ZqzQ4cOhtjcuXPrNRY8g9VqdZqTkJBgaqzExERTea1bt3aaU1xcbGqs6Ohopzk3b940NRYAALh3cGUDAAAAgBY0GwAAAAC0oNkAAAAAoMU9vWcjKirK7viZZ54x5EyaNMkQ8/PzM8QsFoshlpuba3d8/fp1Q859991niD322GOGWEpKit3xmTNnDDkAAOgyevRody9BRET69Onj7iXIX/7yF3cvAWgyuLIBAAAAQAuaDQAAAABa0GwAAAAA0IJmAwAAAIAWd+UG8aCgIEMsOTnZEBs/frzdcWBgYL3nzMrKMsSGDx9ud9y8eXNDjqON3m3atDEVg/uFhoaayjt8+LDTnI4dO5oaKy0tzVTe0KFDneZcuHDB1Fhm6s/sWHCt5557zmVjtWrVymVjiTj+MI36asjP5+quXbvmsrEAALXjygYAAAAALWg2AAAAAGhBswEAAABAC5oNAAAAAFrclRvEx4wZY4jNmDHDZeNnZ2cbYsOGDTPEqj9BPDIy0mVrAAAAADwdVzYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANDirtwg/uijj9brfTk5OYbY8ePHDbHnn3/eEKu+GdyR++67r17rgudq3769qbwTJ044zXn55ZdNjbVhwwZTeV27djWVBwAAoAtXNgAAAABoQbMBAAAAQAuaDQAAAABa0GwAAAAA0OKu3CA+c+ZMQ2zWrFmG2L59++yOz549a8i5cuWKy9bVrl07l40FAAAAeDqubAAAAADQgmYDAAAAgBY0GwAAAAC0uCv3bFy8eNEQe+mllxp/IdUMGDDA3UuAi5l5WJ+IyCOPPOI0JzQ01NRYffv2NZV3//33O80pLi42Nda1a9dM5aHxbdu2zWVjzZgxw2VjiYj06tXLZWPduHHDZWMBABoPVzYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANDirtwg7kpz5841xPz9/es1VnR0tKm8I0eOGGJHjx6t15wAAACAu3BlAwAAAIAWNBsAAAAAtKDZAAAAAKAFzQYAAAAALe6ZDeJWq9UQ+9WvfmV3vHjxYkPOiBEjTI3v5WXs26qqqpy+z9HTzhMSEgyxyspKU+tA42rZsqWpvD//+c9OcyZOnGhqrGbNzP2zbdeundOcd955x9RYZp80DkCPNm3auHsJ0r9/f3cvQUREKioq3L0EiYyMdPcSGlWnTp3cvQSPUVZW5u4lNDlc2QAAAACgBc0GAAAAAC1oNgAAAABoQbMBAAAAQIsmv0G8efPmhlhMTIwhtm3bNkOsQ4cOdselpaWGHEcbuB09zfvBBx80xBxtSq/O0WbfsWPHGmKvv/663bEnbJADAAAAasOVDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtGhSG8R9fHwMMUcbs7dv325qvKSkJLvj9PR0Q87hw4cNseDgYEPM0Xt79OjhdA0hISGG2PLlyw2xCxcu2B3v3LnTkFNeXu50Pphn5gmxjj54wBFH9VFd7969TY21du1aU3mOPiihuvj4eFNjFRQUOM0xu64ffvjBaU5JSYmpsZqq4cOHu2ysuLg4l41VWVnpsrFERPbt2+eysRYuXOiysVJSUlw2FgCgdlzZAAAAAKAFzQYAAAAALWg2AAAAAGjh0Xs2qj+wr/oeCxGR5557ztRYaWlphtjq1avtjh3dS+5oT8WePXsMsejoaEOs+oP3VqxYYchxtK9j9OjRhtimTZvsjj/55BNDTnJysiFWVFRkiDly6tQpU3kAAACAWVzZAAAAAKAFzQYAAAAALWg2AAAAAGhBswEAAABAC4/ZIO7t7W2ILV261O54/vz5hpwbN24YYi+88IIhtmXLFkOs+obwPn36GHLWrFljiDl6WFpWVpYh9oc//MHu+MCBA4acli1bGmKxsbGG2KRJk+yOR40aZcj5+OOPDTFHcnNzDbGIiAhT770bhIaGmsrbu3ev0xxH9eGImQ34mzdvNjXW+fPnTeU5qufqqn8IQ01mzZrlNMfRhxY4Uv3fhSOO/q0AAICmhysbAAAAALSg2QAAAACgBc0GAAAAAC1oNgAAAABo4TEbxB1tQK2+IfzmzZuGnNmzZxti+/btM8T69+9viCUkJNgdP/TQQ4YcPz8/Q2zJkiWG2Pr16w0xRxuxqysuLjbEPvroI6exCRMmGHImTpzodD4RkT/+8Y+m8gAAAICG4MoGAAAAAC1oNgAAAABoQbMBAAAAQAuaDQAAAABaWJRSylSixaJ1IZcuXTLEQkJC7I7Ly8sNOWfOnDHE/P39DbHIyMh6reull14yxJYvX26IVVZW1mv8ps5k+TSYK+svMTHRVN7KlSud5hQWFpoaKycnx2lOamqqqbHefPNNU3n3gsaqPxHX1qCZp6ibFRAQ4LKxNm3a5LKxREQuXrzo0vE8UWPVYPX/D93h2WefdfcSRESkoqLC3UuQjRs3unsJIiKSlZXVKPPExMQ0yjxNQVlZmbuX4DEyMzNN5XFlAwAAAIAWNBsAAAAAtKDZAAAAAKCFxzzU7/Lly4ZY9XtUW7RoYcjp1auXqfH37NljiB06dMjueOfOnYYcR/fa36v7MwAA7lFaWuruJcgbb7zh7iWIiEheXp67lwCgDriyAQAAAEALmg0AAAAAWtBsAAAAANCCZgMAAACAFh6zQTwuLs4Qi4+Ptzvu3bu3IefKlSuG2Lp16wyxoqIiQ8wTHgyExpeSkmIq7/PPP3eak5+fb2qs7OxspzmN+YA6AACAxsCVDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtPCYDeLXr183xDZu3FjrMQAAAADPxZUNAAAAAFrQbAAAAADQgmYDAAAAgBY0GwAAAAC0sCiTjy22WCy614ImqLGeek39wZHGfOo6NQhHGqsGAwICGmWe2vzsZz9z9xJERCQvL8/dS/AYjVV/MTExjTJPU1BWVubuJXiMzMxMU3lc2QAAAACgBc0GAAAAAC1oNgAAAABoQbMBAAAAQAuaDQAAAABa0GwAAAAA0IJmAwAAAIAWNBsAAAAAtKDZAAAAAKAFzQYAAAAALWg2AAAAAGhBswEAAABAC5oNAAAAAFrQbAAAAADQgmYDAAAAgBY0GwAAAAC0oNkAAAAAoAXNBgAAAAAtLEop5e5FAAAAALj7cGUDAAAAgBY0GwAAAAC0oNkAAAAAoAXNBgAAAAAtaDYAAAAAaEGzAQAAAEALmg0AAAAAWtBsAAAAANCCZgMAAACAFv8P4bRvzkfWr3AAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to downscale an image to different sizes\n",
        "def downscale_image(image, downscaled_size):\n",
        "    block_size = 28 // downscaled_size\n",
        "    downscaled = np.zeros((downscaled_size, downscaled_size))\n",
        "    for i in range(downscaled_size):\n",
        "        for j in range(downscaled_size):\n",
        "            # Calculate the average for each block\n",
        "            block = image[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]\n",
        "            downscaled[i, j] = np.mean(block)\n",
        "    return downscaled\n",
        "\n",
        "# Load the dataset (assuming this file is in your working directory)\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "images = data['images']  # a list of 1000 numpy image matrices\n",
        "labels = data['labels']  # a list of 1000 integer labels\n",
        "\n",
        "# Select 3 \"random\" indices from the dataset\n",
        "random_indices = [300, 500, 200]\n",
        "\n",
        "# Downscale the images to multiple sizes and display them\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "for index in random_indices:\n",
        "    fig, axs = plt.subplots(1, len(sizes), figsize=(10, 2))\n",
        "    for ax, size in zip(axs, sizes):\n",
        "        downscaled_image = downscale_image(images[index], size)\n",
        "        ax.imshow(downscaled_image, cmap='gray', vmin=0, vmax=255)\n",
        "        ax.set_title(f'Size {size}x{size}')\n",
        "        ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YePL7s9NyqTw"
      },
      "source": [
        "---\n",
        "# Tasks\n",
        "\n",
        "Your data contains 100 images in each class. When training models, use 80% of training, 10% for validation and 10% for testing. Make sure the data is balanced in each class when splitting.\n",
        "\n",
        "---\n",
        "## Task 1: Linear Classifier [20 points]\n",
        "\n",
        "First, implement a linear classifier. The simplest way to do this is to adapt linear regression approaches that we learned about in class, where the output is a real number. For classification, we can let one category be an output of 1.0 and the other -1.0. Then, after the classifier is trained we can use the sign of the output to determine the predicted class.\n",
        "\n",
        "However, since in MNIST there are multiple classes (10 digits, not just 2), we need to adapt the approach further. We will try both of the following two popular strategies: One-vs-Rest (OvR) and One-vs-One (OvO).\n",
        "\n",
        "**One-vs-Rest (OvR)** is a strategy for using binary classification algorithms for multiclass problems. In this approach, a separate binary classifier is trained for each class, which predicts whether an instance belongs to that class or not, making it the 'one' against all other classes (the 'rest'). For a new input instance, compute the output of all classifiers. The predicted class is the one whose corresponding classifier gives the highest output value.\n",
        "\n",
        "**One-vs-One (OvO)** is another strategy where a binary classifier is trained for every pair of classes. If there are N classes, you will train N(N−1)/2 classifiers. For a new input, evaluate it using all N(N−1)/2​ classifiers. Count the number of times each class is predicted over all binary classifications. The class with the highest count is selected as the final prediction.\n",
        "\n",
        "### Report Results\n",
        "Report the test accuracy for OvR and OvO, for each of the input image sizes, 28x28, 14x14, 7x7, 4x4, 2x2. A table may be helpful. Also report any interesting observations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "\n",
        "# make stables reproductions\n",
        "np.random.seed(0)\n",
        "\n",
        "with open('mini-mnist-1000.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "images = data['images']  # a list of 1000 numpy image matrices\n",
        "labels = np.array(data['labels'])  # a list of 1000 integer labels\n",
        "\n",
        "\n",
        "# split data into : 80% train, 10% validation, 10% testing\n",
        "train_idx, val_idx, test_idx = [], [], []\n",
        "\n",
        "for i in range(10):\n",
        "  idx = np.where(labels == i)[0]\n",
        "  np.random.shuffle(idx)\n",
        "  train_idx.extend(idx[:80])\n",
        "  val_idx.extend(idx[80:90])\n",
        "  test_idx.extend(idx[90:100])\n",
        "\n",
        "train_idx = np.array(train_idx)\n",
        "val_idx = np.array(val_idx)\n",
        "test_idx = np.array(test_idx)\n",
        "\n",
        "def ovr(size):\n",
        "\n",
        "  x = np.array([downscale_image(image, size).flatten() for image in images]) # all features\n",
        "  y = labels # target\n",
        "\n",
        "  # split into traing and testing\n",
        "  x_train,  x_test = x[train_idx], x[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  # OvR\n",
        "  weight_ovr = np.zeros((10, x_train.shape[1]))\n",
        "\n",
        "  # train one binary classifier per class\n",
        "  for i in range(10):\n",
        "    y_binary = np.where(y_train == i, 1.0, -1.0)\n",
        "    # Moore–Penrose pseudoinverse\n",
        "    pinv_x = np.linalg.pinv(x_train)# compute sudo-inverse\n",
        "    # multiply puso-inverse by y_binary\n",
        "    weight_ovr[i] = np.dot(pinv_x, y_binary)\n",
        "\n",
        "  # raw scores of the test set\n",
        "  ovr_scores = np.dot(x_test, weight_ovr.T)\n",
        "  # predict by choosing the hieghtest score\n",
        "  y_predict_ovr = np.argmax(ovr_scores, axis=1)\n",
        "  # compute accurary\n",
        "  ovr_accurary = np.mean(y_predict_ovr == y_test)\n",
        "\n",
        "  return ovr_accurary\n",
        "\n",
        "def ovo(size):\n",
        "\n",
        "  x = np.array([downscale_image(image, size).flatten() for image in images]) # all features\n",
        "  y = labels # target\n",
        "\n",
        "  # split into traing and testing\n",
        "  x_train,  x_test = x[train_idx], x[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  # OvO\n",
        "  # form all class pairs\n",
        "  pairs = list(combinations(range(10), 2))\n",
        "  weight_ovo = {}\n",
        "  # train binary classifiers\n",
        "\n",
        "  for i, j in pairs:\n",
        "    m = (y_train == i) | (y_train == j)\n",
        "    # select only the raws that has labels i or j in the traiing set\n",
        "    y_pair = y_train[m]\n",
        "    x_pair = x_train[m]\n",
        "    # amke the the two-class label into one binary target -1, 1\n",
        "    y_binary = np.where(y_pair == i, 1.0, np.where(y_pair == i, -1.0, 0.0))\n",
        "    # Moore–Penrose pseudoinverse\n",
        "    pinv_x = np.linalg.pinv(x_pair)\n",
        "    # multiply puso-inverse by y_binary\n",
        "    weight_ovo[(i,j)] = np.dot(pinv_x, y_binary)\n",
        "\n",
        "\n",
        "  #predict and compute accurary\n",
        "  y_predict_ovo = []\n",
        "  # iterate over each feature\n",
        "  for x in x_test:\n",
        "    # element vote counter per digit\n",
        "    vote = np.zeros(10, dtype=int)\n",
        "\n",
        "    # iterate over each pair and the weight of each pair\n",
        "    for (i, j) , w in weight_ovo.items():\n",
        "      # favor the class i if its weight is positve\n",
        "      winner = i if w.dot(x) > 0 else j\n",
        "      # add the vote\n",
        "      vote[winner]+=1\n",
        "\n",
        "    # pick the index with the highest vote\n",
        "    y_predict_ovo.append(np.argmax(vote))\n",
        "\n",
        "  # compute accurary\n",
        "  ovo_accurary = np.mean(np.array(y_predict_ovo) == y_test)\n",
        "\n",
        "  return ovo_accurary\n",
        "\n",
        "\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "\n",
        "ovr_results = [ovr(s) * 100 for s in sizes]\n",
        "ovo_results = [ovo(s) * 100 for s in sizes]\n",
        "imag_size = ['28×28', '14×14', '7×7', '4×4', '2×2']\n",
        "\n",
        "accurary_resulsts = pd.DataFrame({\n",
        "    'image size' : imag_size,\n",
        "    'OvR Accuracy (%)': ovr_results,\n",
        "    'OvO Accuracy (%)': ovo_results\n",
        "})\n",
        "print(accurary_resulsts)\n"
      ],
      "metadata": {
        "id": "ueSohSbyCljy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947c1fe8-4de3-4d3d-ddbe-dbbd52dc2ef3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image size  OvR Accuracy (%)  OvO Accuracy (%)\n",
            "0      28×28              54.0              30.0\n",
            "1      14×14              82.0              37.0\n",
            "2        7×7              75.0              34.0\n",
            "3        4×4              64.0              20.0\n",
            "4        2×2              32.0              14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6z07BdyqTw"
      },
      "source": [
        "---\n",
        "## Task 2: Data Augmentation [20 points]\n",
        "\n",
        "Your boss was unhappy with the test accuracy, especially of your 2x2 image classifier, and has made some suggestions. The problem, according to your boss, is that there is not enough data in each input $x$. You are told to augment the data with derived features in order to help the classifier.\n",
        "\n",
        "Specifically, given an input $x$, create additional attributes by computing all of the data up to powers of two. For example, in the 2x2 case your example $x$ consists of four pixel values $x_0$, $x_1$, $x_2$, and $x_3$. Your new input data would have:\n",
        "\n",
        "* all power of zero: 1 (constant)\n",
        "* all powers of one: $x_0$, $x_1$, $x_2$, $x_3$\n",
        "* all powers of two:\n",
        "\n",
        "  $x_0^2$, $x_0 x_1$, $x_0 x_2$, $x_0 x_3$,\n",
        "  \n",
        "  $x_1^2$, $x_1 x_2$, $ x_1 x_3$,\n",
        "  \n",
        "  $x_2^2$, $x_2 x_3$,\n",
        "  \n",
        "  $x_3^2$\n",
        "\n",
        "The data would have 15 values, which has the potential to learn nonlinear relationships between the original inputs, which was not possible before.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "Report the test accuracy for OvR only, with the data augmentation approach, for each of the input image sizes, 28x28, 14x14, 7x7, 4x4, 2x2 (again, perhaps incorporating a table). Report any interesting results or observations.\n",
        "\n",
        "Also, explain to your boss what the danger is of looking at a model's final test accuracy and then suggesting changes to improve it. What should be done instead, if you know you will consider different types of models or hyperparameters in the same model class?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jCvHIrBwyqTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5867cf-78b5-4b89-ec7c-27cf989b6ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image size  OvR Accuracy (%)  OvR Augmentation Accuracy (%)\n",
            "0      28×28              54.0                           88.0\n",
            "1      14×14              82.0                           89.0\n",
            "2        7×7              75.0                           34.0\n",
            "3        4×4              64.0                           66.0\n",
            "4        2×2              32.0                           45.0\n"
          ]
        }
      ],
      "source": [
        "def agumentation(x):\n",
        "  D = len(x)\n",
        "  # constant term\n",
        "  feats = [1.0]\n",
        "  # linear term\n",
        "  feats += list(x)\n",
        "  # all quadratic terms\n",
        "  for i in range(D):\n",
        "      for j in range(i, D):\n",
        "          feats.append(x[i]* x[j])\n",
        "  return np.array(feats)\n",
        "\n",
        "def ovr_agumentation(size):\n",
        "  x_raw = np.array([downscale_image(image, size).flatten() for image in images]) # all features\n",
        "  # apply the augmentation ro the raw downscale images aka features\n",
        "  x = np.array([agumentation(x) for x in x_raw])\n",
        "  y = labels # target\n",
        "\n",
        "  # split into traing and testing\n",
        "  x_train,  x_test = x[train_idx], x[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  # OvR\n",
        "  weight_ovr = np.zeros((10, x_train.shape[1]))\n",
        "  # compute sudo-inverse once for efficiency\n",
        "  pinv_x = np.linalg.pinv(x_train)\n",
        "\n",
        "  for i in range(10):\n",
        "    y_binary = np.where(y_train == i, 1.0, -1.0)\n",
        "    weight_ovr[i] = np.dot(pinv_x, y_binary)\n",
        "\n",
        "\n",
        "\n",
        "  # raw scores of the test set\n",
        "  ovr_scores = np.dot(x_test, weight_ovr.T)\n",
        "  # predict by choosing the hieghtest score\n",
        "  y_predict_ovr = np.argmax(ovr_scores, axis=1)\n",
        "  # compute accurary\n",
        "  ovr_accurary = np.mean(y_predict_ovr == y_test)\n",
        "\n",
        "  return ovr_accurary\n",
        "\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "ovr_results = [ovr(s) * 100 for s in sizes]\n",
        "ovr_aug_results = [ovr_agumentation(s) * 100 for s in sizes]\n",
        "\n",
        "imag_size = ['28×28', '14×14', '7×7', '4×4', '2×2']\n",
        "\n",
        "\n",
        "accurary_resulsts = pd.DataFrame({\n",
        "    'image size' : imag_size,\n",
        "    'OvR Accuracy (%)': ovr_results,\n",
        "    'OvR Augmentation Accuracy (%)': ovr_aug_results\n",
        "})\n",
        "print(accurary_resulsts)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Answer:\n",
        "\n",
        "Looking at the accuracy results and changing features or modesl into out advantage to chase a higher number,\n",
        "the information from the test set has been compromised leading to a over optimistic estimates on how well\n",
        "the model do on unseen data. A better approch will be to include cross-validations feature engennering and\n",
        "hyperparameter tunning so that the final test fold is untouch until the last model evaluation.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz7hMCAkyqTw"
      },
      "source": [
        "---\n",
        "## Task 3: k-Nearest Neighbors Classifier [20 points]\n",
        "\n",
        "Your boss is still unhappy with the results (and still ignoring your advice about not using test data accuracy for model decisions).\n",
        "\n",
        "Next, you are to use the k-nearest neighbors approach to build a classifier for our data. Since we have multiple classes, the one that gets selected can be based on a plurality vote of the $k$ closest samples (whichever category is most frequent). If there are ties, select the class based on the sum of the distances from the test point. For example, if $k=5$, and the closest 5 samples have two pictures that are from category \"1\" and two pictures that are from category \"7\", then you choose the output by computing the sum of the distance from the test point and the two \"5\" samples, as well as the sum of distances from the test point to the two \"7\" samples, and then outputting the class with the smaller total distance.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "For each image size, exhaustively explore different values of $k$ up to 50. Report the best test accuracy. Report the average time taken to do a lookup with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "q7pGs5acyqTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52efb86a-e60b-4b43-fd1b-0163182ecf43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image size  Accurary (%)  Best k  Average time (s)\n",
            "0      28×28          84.0       6          0.001704\n",
            "1      14×14          89.0       4          0.000400\n",
            "2        7×7          85.0       1          0.000161\n",
            "3        4×4          70.0       3          0.000090\n",
            "4        2×2          52.0      13          0.000074\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def eucledian(x, x_train):\n",
        "  return np.sqrt(((x_train - x) ** 2).sum(axis=1))\n",
        "\n",
        "def KNN(size, K=50):\n",
        "  x = np.array([downscale_image(image, size).flatten() for image in images]) # all features\n",
        "  y = labels # target\n",
        "\n",
        "  # split into traing and testing\n",
        "  x_train,  x_test = x[train_idx], x[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "\n",
        "  best_accurary = 0\n",
        "  best_k = 0\n",
        "  best_time = 0\n",
        "\n",
        "  for k in range(1,K+1):\n",
        "    total_time = 0\n",
        "    correct = 0\n",
        "\n",
        "    # iterate over each test sample (x, y_true)\n",
        "    for x, y_true in zip(x_test, y_test):\n",
        "\n",
        "      start = time.time()\n",
        "      # eucledian distance\n",
        "      d = eucledian(x, x_train)\n",
        "      # sort distances from small to large\n",
        "      nn = np.argsort(d)\n",
        "      # only take the k first neighbors\n",
        "      nn = nn[:k]\n",
        "      # get the digit labels of the firs k neighbors\n",
        "      digit_labels = y_train[nn]\n",
        "      # plurarity vote\n",
        "      # count how many votes belong to each class digit\n",
        "      count = np.bincount(digit_labels, minlength=10)\n",
        "      max_count = count.max()\n",
        "      # get all the indices that are in the max_count\n",
        "      indices = np.where(count == max_count)[0]\n",
        "\n",
        "      # ties handeling\n",
        "      if len(indices) > 1:\n",
        "        # pick the class that has the smallest sum distance\n",
        "        sums = { idx: d[nn][digit_labels == idx].sum()  for idx in indices}\n",
        "        predicted = min(sums, key=sums.get)\n",
        "      else:\n",
        "        predicted = indices[0]\n",
        "\n",
        "      # collect metrics\n",
        "      end = time.time()\n",
        "      total_time += end - start\n",
        "      correct += (predicted == y_true)\n",
        "\n",
        "\n",
        "    # compute metrics\n",
        "    accurary = correct / len(y_test)\n",
        "    avg_time = total_time / len(y_test)\n",
        "\n",
        "\n",
        "    # update metrics\n",
        "    if accurary > best_accurary:\n",
        "      best_accurary = accurary\n",
        "      best_k = k\n",
        "      best_time = avg_time\n",
        "\n",
        "  return best_accurary, best_k, best_time\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "imag_size = ['28×28', '14×14', '7×7', '4×4', '2×2']\n",
        "KNN_results = [KNN(s) for s in sizes]\n",
        "KNN_accurary = [r[0] * 100 for r in KNN_results]\n",
        "KNN_k = [r[1] for r in KNN_results]\n",
        "KNN_time = [r[2] for r in KNN_results]\n",
        "\n",
        "accurary_results = pd.DataFrame({\n",
        "    'image size' : imag_size,\n",
        "    'Accurary (%)': KNN_accurary,\n",
        "    'Best k': KNN_k,\n",
        "    'Average time (s)': KNN_time\n",
        "})\n",
        "print(accurary_results)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Task 4: Decision Trees [15 Points]\n",
        "\n",
        "Your boss heard that **decision trees**, **regression trees** and **random forests** are popular in machine learning and wants to see how well they will work on the problem. Adapt one of these approaches (you don't have to do all three) in a way that allows it to make reasonable predictions for this domain, and report what you needed to do. Report your results in terms of test accuracy for the different image sizes in a table. If some of your ideas do not work, report what you tried and why not.\n",
        "\n",
        "**Note 1**: As described in class, decision trees work on categorical attributes, so you will need to adapt things, perhaps by choosing thresholds for the continuous variables in some reasonable way. Describe your thought process and what you did.\n",
        "\n",
        "**Note 2**: Do not use ChatGPT to do the thinking for you. Do not use `scikit-learn` or other ML libraries for this task. Using `numpy`, `scipy`, and `pandas` is okay.\n",
        "\n",
        "**Note 3**: For splitting categorical variables in decision trees, recall from the slides that information in an answer when the prior is $ \\langle P_1, \\ldots, P_n \\rangle $ is $H(P_1, \\ldots, P_n) = -\\sum_{i=1}^{n} P_i \\log_2 P_i $. The suggestion was to use entropy to greedily select which attributes to split on.\n",
        "\n",
        "**Note 4**: If you want to try random forests or regression trees, video lectures will be provided in a Brightspace announcements. Feel free to also read the book and seek online resources, but do not copy over existing code.\n"
      ],
      "metadata": {
        "id": "iGMTKFeMR9kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "- continus to binary : compare each pixel median over the training set\n",
        "- splitting : each pixel will belong to a yes/no group (1-> obove the pixel median, else  -> 0)\n",
        "- impurity measure:  gain = (inpurity before split ) - (weighted impurity after : corresponds to the split into yes/no group  )\n",
        "      gain = (parent) - (  (right child) +  (left child))\n",
        "      gain = (parent) - ( (number of samples on the yes (1) group / # of samples) * right_child ) + ( (number of samples on the no (0) group / # of samples) * left_child)\n",
        "- stopping growing : depth cap, avoid expanding small groups( avoid overfitting due to the children with small data), pure nodes (all classes into one group)\n",
        "- adding limitations to the grow of the tree can help avoid overfititng (specially in size like 28x28)\n",
        "\n",
        "'''\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def entropy(y):\n",
        "  p = Counter(y)\n",
        "  p = np.array(list(p.values())) / len(y)\n",
        "  return -np.sum(p * np.log2(p + 1e-12))\n",
        "\n",
        "class Decision_Tree:\n",
        "  def __init__(self, max_depth=10, min_samples=5):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples = min_samples\n",
        "    self.median = None # pixel median\n",
        "    self.tree = None # root\n",
        "\n",
        "  def new_node(self, x_binary, y, depth):\n",
        "\n",
        "    # check for stopping rules: depth cap, small groups, pure nodes\n",
        "    if depth >= self.max_depth or len(y) < self.min_samples or len(np.unique(y)) == 1:\n",
        "      return ('leaf', Counter(y).most_common(1)[0][0]) # pick the majority class\n",
        "\n",
        "    impurity_before = entropy(y) # parent\n",
        "    best_gain = 0\n",
        "    best_feat = None\n",
        "    # iterate every feature\n",
        "    for i in range(x_binary.shape[1]):\n",
        "      # split into group 1 and 0\n",
        "      group_1 = (x_binary[:, i] == 1) # right child\n",
        "      group_0 = (x_binary[:, i] == 0) # left child\n",
        "\n",
        "      # check for small groups\n",
        "      if np.sum(group_1) < self.min_samples or np.sum(group_0) < self.min_samples:\n",
        "        continue\n",
        "\n",
        "      # calculate each group entopy\n",
        "      right_child = entropy(y[group_1])\n",
        "      left_child = entropy(y[group_0])\n",
        "      n_right = np.sum(group_1)\n",
        "      n_left = np.sum(group_0)\n",
        "      n = len(y)\n",
        "\n",
        "      # compute gain\n",
        "      impurity_after =  ( (n_right / n) * right_child ) + ( (n_left / n) * left_child)\n",
        "      gain = impurity_before - impurity_after\n",
        "\n",
        "      # update metrics\n",
        "      if gain > best_gain:\n",
        "        best_gain = gain\n",
        "        best_feat = i\n",
        "\n",
        "    # none of the features produce a pos gain\n",
        "    if best_feat is None:\n",
        "      return ('leaf', Counter(y).most_common(1)[0][0])\n",
        "\n",
        "    # split again\n",
        "    group_1 = (x_binary[:, best_feat] == 1) # right child\n",
        "    group_0 = (x_binary[:, best_feat] == 0) # left child\n",
        "    right_subtree = self.new_node(x_binary[group_1], y[group_1], depth + 1)\n",
        "    left_subtree = self.new_node(x_binary[group_0], y[group_0], depth + 1)\n",
        "    return ('node', best_feat, left_subtree, right_subtree)\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, x , y):\n",
        "    # compute the media of each pixel\n",
        "    self.median = np.median(x, axis=0)\n",
        "    # apply the binary-logic to the training set\n",
        "    x_binary = (x >= self.median).astype(int)\n",
        "    # build the tree\n",
        "    self.tree = self.new_node(x_binary, y, depth=0)\n",
        "\n",
        "  def predict_(self, x):\n",
        "    # binary-logic to the training set\n",
        "    x_binary = (x >= self.median).astype(int)\n",
        "    node = self.tree # root\n",
        "    while node[0] == 'node':\n",
        "      node_type, feat, left, right = node\n",
        "      if x_binary[feat] == 0:\n",
        "        node = left\n",
        "      else:\n",
        "        node = right\n",
        "\n",
        "    return node[1]\n",
        "\n",
        "\n",
        "  def predict(self,X):\n",
        "    return np.array([self.predict_(x) for x in X])\n",
        "\n",
        "\n",
        "sizes = [28, 14, 7, 4, 2]\n",
        "\n",
        "results = []\n",
        "for size in sizes:\n",
        "  x = np.array([downscale_image(image, size).flatten() for image in images]) # all features\n",
        "  y = labels # target\n",
        "\n",
        "  # split into traing and testing\n",
        "  x_train,  x_test = x[train_idx], x[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  decision_tree = Decision_Tree(max_depth=10, min_samples=5)\n",
        "  decision_tree.fit(x_train, y_train)\n",
        "  y_predict = decision_tree.predict(x_test)\n",
        "  accuracy = np.mean(y_predict == y_test)\n",
        "\n",
        "  results.append({\n",
        "        'image size': f'{size}x{size}',\n",
        "        'Decisioin tree Accuracy (%)': accuracy * 100\n",
        "    })\n",
        "\n",
        "\n",
        "print(pd.DataFrame(results))\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Using median split to go from continous to binary on every pixel, gave me as many features as pixels (eg: 28x28 -> 784, 14x14 -> 196 etc).\n",
        "After all pixesl were split into each group, the stopping rules prevented some samples to be expanded, specially in high resolutions (many splits with small children)\n",
        "\n",
        "14x14 and 7x7 perpormed better than 28x28 because all features in 28x28 were not used in 10 labels(depth)\n",
        "the 2x2 was too small to split into 10 classes which explains the low performance\n",
        "\n",
        "To conclude, on high resolutions the tree didn't have enough splits (depth) before it get to use all features, which lead to underfitting. On the other side,\n",
        "on small resolutions even when more splits were avilable with fewer features, the splits wee not enough. Lastly, it seems to be that the stoppings rules are\n",
        "limmiting the grow (eg: min_samples=5) which blocked nodes with fewer points\n",
        "\n",
        "improvenments:\n",
        "          1) by giving each pixel multiple threshold (other than median), perhaps increasing the number of features in which the same depth=10 can explore more\n",
        "          2) tweak the max_depth to a higher split (if multiple threshold was introduced)"
      ],
      "metadata": {
        "id": "Mbr8m4BYULsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d047eb9d-0f7b-46fa-8d00-6906d2437394"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image size  Decisioin tree Accuracy (%)\n",
            "0      28x28                         62.0\n",
            "1      14x14                         69.0\n",
            "2        7x7                         69.0\n",
            "3        4x4                         55.0\n",
            "4        2x2                         28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyN1oAczyqTw"
      },
      "source": [
        "---\n",
        "## Task 5: Neural Networks [25 Points]\n",
        "\n",
        "Next, your boss wants you to try neural networks. Rather than using a library to do the training for you, you will **only** use `pytorch` to perform backpropagation and compute gradients. Using activation functions like `torch.sigmoid` or `torch.softmax` is allowed, as you need to do this for computing gradients. You can write your own high-level neural network class if desired, don't use anything from `pytorch` for that.\n",
        "\n",
        "\n",
        "An example network and how to compute gradients with pytorch is shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVYHnm2fyqTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbbd6d3-1316-4fcc-b43d-8218569ba8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Output: tensor([0.5348, 0.2167, 0.2485], grad_fn=<SoftmaxBackward0>)\n",
            "Desired Output: tensor([1., 0., 0.])\n",
            "Initial loss: 0.625852644443512\n",
            "Gradient for weights matrix W1: tensor([[-2.9431e-03, -5.8862e-03, -8.8293e-03],\n",
            "        [ 4.1993e-03,  8.3986e-03,  1.2598e-02],\n",
            "        [-3.0524e-06, -6.1048e-06, -9.1572e-06]])\n",
            "New loss after updating weights and biases: 0.6079817414283752\n"
          ]
        }
      ],
      "source": [
        "# Example of using pytorch to compute gradients and updates weights and biases\n",
        "#\n",
        "# The network consists of:\n",
        "# 1. An input layer with 3 features.\n",
        "# 2. A first hidden layer with 3 neurons. Each neuron in this layer performs a linear transformation\n",
        "#    on the input data using a weight matrix (W1) and a bias vector (b1). This is followed by a sigmoid\n",
        "#    activation function.\n",
        "# 3. A second hidden layer, also with 3 neurons, which processes the output of the first layer. Similar\n",
        "#    to the first layer, it uses a weight matrix (W2) and a bias vector (b2) for linear transformation,\n",
        "#    followed by a softmax activation function. The softmax activation is used here to normalize the\n",
        "#    output of the second layer into a probability distribution over the three classes. This is particularly\n",
        "#    useful for multi-class classification problems.\n",
        "# 4. The network uses cross-entropy as the loss function, which is a common choice for classification tasks\n",
        "#    involving softmax outputs. This loss function compares the predicted probability distribution with the\n",
        "#    true distribution (one-hot encoded) and penalizes the predictions that diverge from the actual labels.\n",
        "#\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "# Initialize input, weights, and biases\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "W1 = torch.tensor([[0.1, 0.2, 0.5],\n",
        "                  [-0.1, -0.5, -1.1],\n",
        "                  [0, 7.5, -1.1]], requires_grad=True)\n",
        "b1 = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "W2 = torch.tensor([[0.1, -0.3, 0.4],\n",
        "                  [0.2, 0.4, -0.6],\n",
        "                  [-0.1, 0.5, -0.2]], requires_grad=True)\n",
        "b2 = torch.tensor([0.0, 0.0, 0.0], requires_grad=True)\n",
        "\n",
        "# Target output\n",
        "y_true = torch.tensor([1.0, 0.0, 0.0])\n",
        "\n",
        "# Forward pass through first layer\n",
        "z1 = torch.matmul(W1, x) + b1\n",
        "a1 = torch.sigmoid(z1)  # Sigmoid activation\n",
        "\n",
        "# Forward pass through second layer\n",
        "z2 = torch.matmul(W2, a1) + b2\n",
        "a2 = torch.softmax(z2, dim=0)  # Softmax activation\n",
        "\n",
        "print(\"Initial Output:\", a2)\n",
        "print(\"Desired Output:\", y_true)\n",
        "\n",
        "# Compute loss (Cross-entropy): https://en.wikipedia.org/wiki/Cross-entropy\n",
        "loss = -torch.sum(y_true * torch.log(a2))\n",
        "print(\"Initial loss:\", loss.item())\n",
        "\n",
        "# Backpropagation\n",
        "loss.backward()\n",
        "\n",
        "# you can print out gradient for each element now\n",
        "print(\"Gradient for weights matrix W1:\", W1.grad)\n",
        "\n",
        "# Update weights and biases based on gradient (should reduce loss)\n",
        "learning_rate = 0.02\n",
        "\n",
        "# the no_grad() environment is needed to indicate that the computation should not\n",
        "# be part of the gradient computation\n",
        "with torch.no_grad():\n",
        "    W1 -= learning_rate * W1.grad\n",
        "    b1 -= learning_rate * b1.grad\n",
        "    W2 -= learning_rate * W2.grad\n",
        "    b2 -= learning_rate * b2.grad\n",
        "\n",
        "# After the update, clear the gradients (in case we want to compute them again later)\n",
        "W1.grad.zero_()\n",
        "b1.grad.zero_()\n",
        "W2.grad.zero_()\n",
        "b2.grad.zero_()\n",
        "\n",
        "# Forward pass with updated weights and biases\n",
        "z1 = torch.matmul(W1, x) + b1\n",
        "a1 = torch.sigmoid(z1)  # Sigmoid activation\n",
        "z2 = torch.matmul(W2, a1) + b2\n",
        "a2 = torch.softmax(z2, dim=0)  # Softmax activation\n",
        "\n",
        "# Compute new loss\n",
        "new_loss = -torch.sum(y_true * torch.log(a2))\n",
        "print(\"New loss after updating weights and biases:\", new_loss.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above updates the parameters based on a single piece of data, but often multiple inputs are used and their gradient is averaged when updating a model.\n",
        "\n",
        "Your task is to write the training code for the different neural network architectures proposed and report accuracy. Start with all random parameters between -1 and 1. Training should stop when the accuracy, as measured on the validation data, no longer appears to be improving. You can plot the validation data accuracy over time to ensure this looks correct. If this takes too long but it appears the model is still improving in accuracy, consider increasing the learning rate (start with 0.02 as in the example).\n",
        "\n",
        "For the gradient, you are to compute the gradient over the full set of training data, and then average them together before you update. Then, repeat with mini-batches of size 100, with 10 random samples from each class. This should update the model weights faster, but may require more updates to get the accuracy down.\n",
        "\n",
        "### Report Results\n",
        "\n",
        "Provide at least one plot of your validation data accuracy going down over time as training progresses. What was the condition you decided to use to detect if training should stop? How many updates were needed in the case of your plot?\n",
        "\n",
        "\n",
        "Create a table where each row corresponds to one model and training method (mini-batch or full). Use the 7x7 version of the data (49-dimensional inputs). You are to explore the following models: the number of hidden layers can be varied between 2 and 4. Each layer's size can be 16, 32, or 64 neurons (all hidden layers have the same number of neurons). Explore three different activation functions for the network, ReLU (`torch.relu`), arctan (`torch.atan`), and sigmoid (`torch.sigmoid`). After the final layer, use a softmax rather than the normal network activation function, to ensure all outputs are between 0 and 1. There should be 10 outputs, one for each class in the MNIST data.\n",
        "\n",
        "In the table, report the architecture, training time, number of model updates and test accuracy. What is the best architecture? Did mini-batches help with anything? Report any other interesting observations.\n",
        "\n"
      ],
      "metadata": {
        "id": "hddWtjp7bHvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x = np.array([downscale_image(image, 7).flatten() for image in images]) # all features\n",
        "y = labels # target\n",
        "\n",
        "# set up torch tensors\n",
        "x_train, x_test, x_values = torch.tensor(x[train_idx], dtype=torch.float32), torch.tensor(x[test_idx], dtype=torch.float32), torch.tensor(x[val_idx],dtype=torch.float32)\n",
        "y_train, y_test, y_values = torch.tensor(y[train_idx], dtype=torch.long ), torch.tensor(y[test_idx], dtype=torch.long), torch.tensor(y[val_idx], dtype=torch.long)\n",
        "\n",
        "# encode vectors via one-hot\n",
        "def one_hot(labels , class_num=10):\n",
        "  # create a new tensor size (n x number of classes)\n",
        "  n = labels.size(0)\n",
        "  temp_tensor = torch.zeros(n, C, dtype=torch.float32)\n",
        "  for i in range(n):\n",
        "      temp_tensor[i, labels[i]] = 1.0\n",
        "  return temp_tensor\n",
        "\n",
        "y_train_one_hot = one_hot(y_train)\n",
        "\n",
        "class Neural_Networks:\n",
        "  def __init__(self, layers_sizes, activation):\n",
        "    self.activation = activation\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "    # pair up each layer size with its sucessor\n",
        "    for inner, outter in zip(layers_sizes[:-1], layers_sizes[1:])\n",
        "      weight = torch.empty(outter, inner).uniform_(-1,1).requires_grad_(True)\n",
        "      bias = torch.empty(outter).uniform_(-1,1).requires_grad_(True)\n",
        "      self.weights.append(weight)\n",
        "      self.biases.append(bias)\n",
        "\n",
        "  def foward(self, x):\n",
        "    output = x\n",
        "    # go trhought each hidden layer\n",
        "    for weight, bias in zip(self.weights[:-1], self.biases[:-1]):\n",
        "      linear_m = np.dot(output,weight.T + bias)\n",
        "      # apply non-linear activation\n",
        "      output = self.activation(linear_m)\n",
        "    logits = np.dot(output, self.weights[-1].T) + self.biases[-1]\n",
        "    # turn raw scores into probabiliy distibution\n",
        "    return torch.softmax(logits, dim=1)\n",
        "\n",
        "\n",
        "def balance_data(data,batch_size=100 ):\n",
        "  for c in data:\n",
        "            np.random.shuffle(data[c])\n",
        "        # one batch per class-block\n",
        "        for _ in range(len(y_train)//batch_size):\n",
        "            batch_idx = []\n",
        "            for c in range(10):\n",
        "                batch_idx += data[c][:batch_size//10].tolist()\n",
        "            x_binary = x_train[batch_idx]\n",
        "            y_binary = y_train[batch_idx]\n",
        "            y_binary_one_hot = one_hot(y_binary)\n",
        "  return x_binary, y_binary, y_binary_one_hot\n",
        "\n",
        "\n",
        "\n",
        "def gradient_descent(model, learning_rate=0.02, epochs=5, max_epochs=50, shuffle=False):\n",
        "    best_validation = 0.0\n",
        "    epoch_count = 0 # counts how many consecutive epochs have pass without any improvement\n",
        "    validation_accuracies = [] # records each validation accuracy at each epoch\n",
        "    if shuffle:\n",
        "      # pre compute indices to balance the data\n",
        "      per_class = {c: np.where(y_train.numpy()==c)[0] for c in range(10)}\n",
        "    start = time.time()\n",
        "    updates = 0\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "\n",
        "      if shuffle:\n",
        "          x_train, y_train, y_train_one_hot = balance_data(per_class)\n",
        "\n",
        "\n",
        "        # foward pass on the training set\n",
        "        prediction = model.forward(x_train)\n",
        "        # calculate the entropy loss\n",
        "        loss = -torch.sum(y_train_one_hot * torch.log(prediction)) / len(y_train)\n",
        "\n",
        "        # clear any hangling gradiants from other epochs\n",
        "        for weight, bias in zip(model.weights, model.biases):\n",
        "            if weight.grad is not None: weight.grad.zero_()\n",
        "            if bias.grad is not None: bias.grad.zero_()\n",
        "\n",
        "        # backward pass on every weight and bias on the model\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "          # update the paramemters\n",
        "            for weight, bias in zip(model.weights, model.biases):\n",
        "                weight -= learning_rate * weight.grad\n",
        "                bias -= learning_rate * bias.grad\n",
        "        updates+=1\n",
        "        # foward pass on the validation set\n",
        "        val_predictions = torch.argmax(model.forward(x_values), dim=1)\n",
        "        # calculate validation accuracy\n",
        "        val_accuracy = (val_predictions==y_values).float().mean().item()\n",
        "        # record the accuracy for the epoch\n",
        "        validation_accuracies.append(val_accuracy)\n",
        "\n",
        "        # update metrics\n",
        "        if val_accuracy > best_validation:\n",
        "            best_validation= val_accuracy\n",
        "            epoch_count = 0\n",
        "        else:\n",
        "            epoch_count += 1\n",
        "        if epoch_count >= epochs:\n",
        "            break\n",
        "\n",
        "    total_time = time.time() - start\n",
        "    accuracy = (torch.argmax(model.forward(x_test),dim=1)==y_test).float().mean().item()\n",
        "    return validation_accuracies, epoch, total_time, accuracy, updates\n"
      ],
      "metadata": {
        "id": "GxJf4LR8f54p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "63b07ab7-f885-4fb0-9e23-dc4e6ed708e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-1-0193d887d70c>, line 25)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-0193d887d70c>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    for inner, outter in zip(layers_sizes[:-1], layers_sizes[1:])\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-0LPr5QfskFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}